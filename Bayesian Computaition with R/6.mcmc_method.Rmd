---
title: "6. Markov Chain Monte Carlo Methods"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Cmd+Shift+Enter*. 

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Cmd+Option+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Cmd+Shift+K* to preview the HTML file). 

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

### Import the library
```{r}
library(LearnBayes) # package for the book
library(kableExtra) # for display table in HTML format
```

## 6.1 Introduction
In Chapter 5 we have seen some sampling techniques for simulation in Bayesian inference, e.g. sampling from the posterior. However, all of them (i.e. rejection sampling, impotance sampling and SIR algorithm) require a **suitable proposal density $p$**, and this choice can be difficult. 

In this chapter, we introduce Markov Chain Monte Carlo (MCMC) algorithms in summarizing posterior distribution. MCMC is very attractive because:

- easy to to set up
- easy to program
- requires relatively lttile prior info

In the following sections we see:

- 6.2: Simple random walk
- 6.3: Two variants of the Metropolis-Hastings algorithms
- 6.4: Gibbs sampling

## 6.2 Introduction to Discrete Markov Chains
Consider the following random walk problem. 

- a person takes a value in [1,...,6]
- if she is in interiors, the probabilities of stay, or move (to left or right) are equal
- if she is in edges, the probabilities stay or move to adjecent number are equal

This is a simple example of a discrete Markov chain. The transition matrix $P$ is given by:
$$
P=\begin{bmatrix}
.5 & .5 & 0 & 0 & 0 & 0 \\
.25 & .5 & .25 & 0 & 0 & 0 \\
 0 & .25 & .5 & .25 & 0 & 0 \\
 0 & 0 & .25 & .5 & .25 & 0 \\
 0 & 0 & 0 & .25 & .5 & .25 \\
 0 & 0 & 0 & 0 & .5 & .5 
\end{bmatrix}
$$

Here are some properties of Markov chain:

- *irreducible*: possible to go from any state to any state in one or more steps
- *periodic*: given a perticular state, a person can only return to the current state at regular intervals, if not it is said *aperiodic* (the random walk example is this case)

We can represent one's current position by probabilities:
$$
p = (p_1,p_2, ..., p_6)
$$
where $p_i$ is the prob that the person is in state $i$ now. If $p^j$ is the person's location at step $j$, the next position is given by
$$
p^{j+1} = p^j P.
$$
Suppose we can find a probability vector $w$ s.t.:
$$
w = wP
$$
then, $w$ is said to be the *stationaly* distribution. If a Markov chain is irreducible and aperiodic, then it has a *unique* stationaly distribution. (also the limiting distribution of this chain will be $w$)

We test it in our example. 
```{r}
# transition matrix P
P = matrix(c(.5 , .5 , 0 , 0 , 0 , 0 , .25 , .5 , .25 , 0 , 0 , 0 , 0 , .25 , .5 , .25 , 0 , 0 , 0 , 0 , .25 , .5 , .25 , 0 ,0 , 0 , 0 , .25 , .5 , .25 , 0 , 0 , 0 , 0 , .5 , .5), 
           nrow = 6, ncol = 6, byrow = T) 
P
```
Suppose we start at location 3. 
```{r}
s = array(0, c(50000,1))
s[1] = 3 # initial location
```
We simulate 50000 draws from the Markov chain. 
```{r}
for (j in 2:50000){
  s[j] = sample(1:6, size = 1, prob = P[s[j-1],]) # trans prob is  P[s[j-1],] from previous state s[j-1]
} 
```
We summarize the frequencies of visit after 500, 2000, 8000, and 50000 steps.
```{r}
m = c(500, 2000, 8000, 50000)
for (i in 1:length(m)){
  print(table(s[1:m[i]])/m[i])
}
```
We observe that the relative frequencies of the states are converging to $w=(.1,.2,.2,.2,.2,.1)$, which is the stationaly distribution. We can confirm by checkning $wP$ will be $w$. 
```{r}
w = matrix(c(.1,.2,.2,.2,.2,.1), nrow = 1, ncol = 6)
w%*%P  # %*%: matrix multiplication
```


## 6.2 Metropolis-Hastings Algorithms
The MCMC essentially is a continuous-valued generalization of the discrete Markov chain set up described in the previous section.  The MCMC sampling sets up and irreducivle, aperiodic Markov chain fro which the *stationary distribution equals the posterior distribution of interest*. The Metropolis-Hastings (MH) algorithm is used to construct such Markov chain. In this section we consider the two types of it: independence chain and random walk chain. 

Suppose we want to simulate from a post $g(\theta|y) = g(\theta)$.  A MH algorithm begins with an inital value $\theta^0$ and specifies a rule for simulating t-th value $\theta^t$ given the (t-1)st value $\theta^{t-1}$. This rule consists of a **proposal density**, which simulates a candidate value $\theta^*$, and the coputation of an **acceptance probability** $P$, which indicates the prob that the candidate value $\theta^*$ will be accepted as the next value or not. Concretely,

- Simulate a candidate value $\theta^*$ from a proposal density $p(\theta^*|\theta^{t-1})$ 
- Compute the ratio $R$ (see https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm#Formal_derivation for more details):
$$
R = \frac{g(\theta^*)p(\theta^{t-1}|\theta^*)}{g(\theta^{t-1})p(\theta^*|\theta^{t-1})}
$$
- Compute the acceptance prob $P= \min\{R,1\}$.
- Sample a value $\theta^t$ s.t. $\theta^t=\theta^*$ with prob $P$; otherwise $\theta^t=\theta^{t-1}$

Under some conditions on the proposal density $p(\theta^*|\theta^{t-1}$, the simulated draws $\theta_1,\theta_2,...$ will **converge to a r.v. that is distributed according to $g(\theta)$.**

*More on the acceptance rate*: We want to find a probability $p$ such that:
$$
g(x)p(y|x) = g(y)p(x|y)
$$
where left = prob(getting y from x) and right = prob(getting x from y). We call this as *reversibility condition*. However, most of the cases we have:
$$
g(x)q(y|x) > g(y)q(x|y)
$$
or the opposite ($<$). It says "getting y from x is too often while getting x from y is too rare". Hence we want to somehow *correct* this condition by introducing an acceptance rate $A(x, y)<1$. We can see $A(x, y)<1$ as *probability of move*. The transition from x to y is given by
$$
p_{HM}(y|x) = A(x, y)q(y|x)
$$
where $A(x, y)<1$ is not defined yet. From the above inequality, we should set $A(y, x)=1$, i.e. transition from y to x must occures more. On the other hand, the prob of move from x to y should satisfy the reversibility condition for $p_{HM}$, hence,
$$
\begin{aligned}
g(x) A(x, y)q(y|x) &=  g(y)A(y, x)q(x|y)\\
&= g(y)q(x|y)
\end{aligned}
$$
Thus we have:
$$
A(x, y) = \begin{cases}\min \{1,\frac{g(y)q(x|y)}{g(x)q(y|x)}  \}, g(x)q(y|x)>0\\
1, \text{otherwise}
\end{cases}
$$

#### Independent case
If the proposal density $p$ is independent of the current state: 
$$
p(\theta^*|\theta^{t-1})  =p(\theta^*)
$$
then the algorithm is called an *independence chain*. This can be implemented by `indepmetrop` in `LearnBayes`

#### Symmetric case (random walk)
If the proposal density $p$ is symmetric density:
$$
p(\theta^*|\theta^{t-1})  = h(\theta^*-\theta^{t-1})
$$
where $h$ is a  symmetric density about the origin, then this type of *random walk* chain has the ratio $R$ s.t.:
$$
R = \frac{g(\theta^*)}{g(\theta^{t-1})}
$$
 This can be implemented by `rwmetrop` in `LearnBayes`.
 
 Desireble features of $p$ depends on the choice of MCMC algorithm. We need to be careful about the rate $g/p$ to be bounded as befor. The proposal $p$ is "best" if the acceptance ratio ranges between 25%-45% (but depends on the dimension). 
 
 ### 6.4 Gibbs Sampling
 Another setting up of MCMCis Gibbs sampling. Suppose our interest parameter is $\theta=(\theta_1,...,\theta_d)$. The joint posterior $[\theta|data]$ may be of high dim and difficult to simulate. Hence we set the following set of $d$ conditional distributions:
 $$
 [\theta_1|\theta_2,...,\theta_d,data],\\
 [\theta_2|\theta_1,\theta_3,...,\theta_d,data],\\
 ...\\
 [\theta_d|\theta_1,...,\theta_{d-1},data],\\
 $$
 The idea of Gibbs sampling is that we can set up a Markov chain simulation algorithm from the joint posterior by successfully simulating individual params from the set of $d$ conditional distributions. It is known that *under general conditions, draws from this simulation will converge to the target distirubiton $[\theta|data]$*. 
 
In cases where it is not convenient to sample directly from the conditional dist, one can apply a MH algorithm with a random walk proposal. Suppose $\theta^t_i$ is the current value of $i$th componet of the parameter vector, and let $g(\theta_i)$ be the conditional dist with suppressed dependence of $\theta_{(-i)}$. Then one possible approach of giving a candidate value is:
$$
\theta_i^* = \theta_i^t + c_i Z_i
$$
where $c_i$ is a scale constant and $Z_i$ is a standard normal r.v.. The next value $\theta_i^{t}$ will be $\theta^*$ with probability $P=\min\{1,g(\theta^*)/g(\theta^{t})\}$; otherwise $\theta_i^{t+1} = \theta_i^{t}$. This process can be implemeted by the `R` function `gibbs` in `LearnBayes`.

## 6.5 MCMC Output Analysis 
Although the theoreis give that the j-th simulation $\theta^j$ converges to a draw from the true posterior if $j$ goes infinity, there is no practical guidance on it. Hence, we need to assess the performance by plotting or computing diagnostic statistics etc..

## 6.7 Learning About a Normal Population from Grouped Data
The first example: random sample taken from a normal populatino with mean $\mu$ and std $\sigma$, but only observes in "grouped" form. Our problem is about the mean and std of the heights of men from a local college. 

Height interval (in.)/ Frequency

- < 66 / 14
- [66, 68] / 30
- [68, 70] / 49
- [70, 72] / 70
- [72, 74] / 33
- < 74 / 15

We observe the unknow bin probs: $p_i,i=1,...,6$. e.g. the heigth is in [66,68] is given by $p_2 = \Phi(68,\mu,\sigma) - \Phi(66,\mu,\sigma)$, where $\Phi(;,\mu,\sigma)$ is the cdf of Normal. The likelihood is given as:
$$
\begin{aligned}
L(\mu,\sigma) & \propto \Phi(66,\mu,\sigma)^{14}(\Phi(68,\mu,\sigma)-\Phi(66,\mu,\sigma))^{30}\\
& \times  (\Phi(70,\mu,\sigma)-\Phi(68,\mu,\sigma))^{49} \\
&  \cdots\\
& \times  (1-\Phi(74,\mu,\sigma))^{15}
\end{aligned}
$$
Suppose $(\mu,\sigma)$ are assigned the usual noniformative prior, then the posterior is proportional to 
$$
g(\mu,\sigma) \propto \frac{1}{\sigma}L(\mu,\sigma).
$$
To make the params to be real-valued line, $\lambda = \log(\sigma)$, and the posterior of $(\mu,\lambda)$ is given by
$$
g(\mu,\lambda) \propto L(\mu, \exp(\lambda)).
$$
Here we define a function `groupeddatapost` that computes the log of the post of $(\mu,\lambda)$. 
```{r}
groupeddatapost = function(theta,data){ 
  # theta: (mu, lambda), 
  # data$int.lo: lower bound, data$int.hi: higher bound, data$f: frequency
  dj = function(f, int.lo, int.hi, mu, sigma){
    f * log(pnorm(int.hi, mu, sigma) - pnorm(int.lo, mu, sigma))
  }
  mu = theta[1]
  sigma = exp(theta[2])
  sum(dj(data$f, data$int.lo, data$int.hi, mu, sigma))
}
```
We define the data
```{r}
d = list(int.lo = c(-Inf, seq(66,74, by = 2)),
         int.hi = c(seq(66,74, by = 2), Inf),
         f = c(14, 30, 49, 70, 33, 15))
```
To decide the *initial point* (to use the function `laplace`), we require a good guess at the location of the post mode. To estimate the mode of $(\mu, \log \sigma)$, we replace the bin to the mid-point. Then, use the sample mean and std of the artificial data.
```{r}
y = c(rep(65,14), rep(67,30), rep(69,49), rep(71,70),rep(73,33),rep(75,15))
mean(y)
```
```{r}
log(sd(y))
```
Based on this, we believe that $(\mu, \log \sigma) \approx (70,1)$. We find the posterior by using `laplace`.
```{r}
start = c(70,1)
fit = laplace(groupeddatapost, start, d) #Summarization of a posterior density by the Laplace method
fit
```
Hence the posterior mode of $(\mu, \log \sigma)$ is found to be (70.17,0.97). The associated stds can be computed as:
```{r}
modal.sds = sqrt(diag(fit$var)) # sqrt of diag of the covariance matrix
modal.sds
```
We use this result to design a MH random walk algorithm. For the *proposal density* $p$, we use **t-distribution** with the covariance matrix of `laplace` and the scale parameter 2 . We run 10000 iterations of the random walk algorithm starting from `start`. 
```{r}
proposal = list(var=fit$var, scale=2)
fit2 = rwmetrop(groupeddatapost, proposal, start, 10000, d) # run the HM random walk algo
```
We monitor the algorithm by the acceptance rate $R$.
```{r}
fit2$accept
```
We now be able to summarize the params by computing the posterior means and stds.
```{r}
post.means = apply(fit2$par,2,mean)
post.sds = apply(fit2$par,2,sd)
```
We can access the accuracy of the model by comparing the result of `laplace` (optimization).
```{r}
cbind(post.means, post.sds) # result of MCMC
```
```{r}
cbind(c(fit$mode),modal.sds) # result of laplace (optimization)
```
Finally we see the result by plotting.
```{r}
mycontour(groupeddatapost, c(69,71,0.6,1.3),data = d,
          xlab="mu",ylab="log sigma")
points(fit2$par[5001:10000,1],fit2$par[5001:10000,2]) # plot the last 5000 samples
```


## 6.8 Example of Output Analysis
In order to perform the output analysis of MCMC algorithm, we use `coda` which will be described in chapter 11. Suppose we rerun the MH rw algorthm for the previous problemw with **poor choices of initial value and proposal density $p$**. We set the inital as (65,1) (instead of (70,1)) and the scale of 0.2 of $p$  (instead of 2).
```{r}
start = c(65,1)
proposal = list(var = fit$var, scale = 0.2)
```
We then rerun the algo.
```{r}
bayesfit = rwmetrop(groupeddatapost, proposal = proposal, start = start, m = 10000, d)
bayesfit$accept
```
We observe that acceptance rate of 89% which is pretty high. In this example we consider the first 2000 iterations as the burn-in period thus dicard them. 
```{r}
library(coda) # for assessing the MCMC result
library(lattice) # for xyplot
dimnames(bayesfit$par)[[2]] = c("mu","log sigma")
xyplot(mcmc(bayesfit$par[-c(1:2000),]),col="black")
```

We observe that the simulated draws reached the main support of the posterior of $\mu$. However, the sequence appears irregular: it explores  $\mu > 70.5$ for a while which is not relevant. We hence see the strong autocorrelation 
```{r}
#par(mfrow=c(2,1))
autocorr.plot(mcmc(bayesfit$par[-c(1:2000),]),auto.layout = T)
```
The autocorrelations are close to 1 in Lag1, and decrease very slowly.

The `summary` of `mcmc` output gives the empirical mean and sd for each param. The `Naive SE` is computed as the draws are fully independent sample ($\sigma_{SE} = \sigma/\sqrt{n}$), hence the value is very small (e.g. 0.002 for $\mu$) . However, `BatchSE` gives the more more accurate estimate. (we assume *a batch of data* is independent)
```{r}
 summary(mcmc(bayesfit$par[-c(1:2000),]))
 batchSE(mcmc(bayesfit$par[-c(1:2000),]), batchSize=50) # batch size = 50
```
We compare this result with the previously obtained more accurate one (start point = (70,1), scale of $p$ is 2)
```{r}
 summary(mcmc(fit2$par[-c(1:2000),]))
 batchSE(mcmc(fit2$par[-c(1:2000),]), batchSize=50) # batch size = 50
```
We see that `batchSE` are now very small. Also check by plotting. 
```{r}
dimnames(fit2$par)[[2]]=c("mu","log sigma")
xyplot(mcmc(fit2$par[-c(1:2000),]),col="black")  # result of samples
```
```{r}
autocorr.plot(mcmc(fit2$par[-c(1:2000),]),auto.layout = T) # autocorr
```

The parameters appear more *random noise*. For the autocorrelation, it is near 1 for lag 1 and decreases very rapidly. 


## 6.9 Modeling Data with Cauchy Errors
The second example is to see what happens with **outliers**.
We here test a Cauchy density (t distribution with a single degree of freedom). 

Suppose we observe data $y_i$ from a Cauchy density of location paramter $\mu$ and scale paramter $\sigma$,
$$
f(y|\mu,\sigma) = \frac{1}{\pi \sigma(1+z^2)}
$$
where $z = \frac{y-\mu}{\sigma}$. Suppose we use the usual noninformative prior:
$$
g(\mu,\sigma) \propto \frac{1}{\sigma}
$$
Then, the posterior is given by:
$$
\begin{aligned}
g(\mu,\sigma|data)& \propto g(\mu,\sigma) \prod_{i}f(y_i|\mu,\sigma)\\
& =  \frac{1}{\sigma} \prod_{i}[\frac{1}{\sigma(1+(\frac{y_i-\mu}{\sigma})^2)}]
\end{aligned}
$$
As always, we replace the variable $\sigma$ by $\lambda = \log(\sigma)$.
$$
\begin{aligned}
g(\mu,\lambda|data) &\propto  \prod_{i}[\frac{1}{e^\lambda(1+(\frac{y-\mu}{e^\lambda})^2)}]\\
& = \prod_{i}[\frac{e^\lambda}{e^{2\lambda} + (y_i-\mu)^2}]
\end{aligned}
$$
The log of the density is:
$$
\log(g(\mu,\lambda|data)) = \sum_i [\lambda - \log(e^{2\lambda} + (y_i-\mu)^2)]
$$ 
We define the funtion `cauchyerrorpost_mine` (`LearnBayes` has `cauchyerrorpost`) to compute $\log(g(\mu,\lambda|data))$:
```{r}
cauchyerrorpost_mine = function(theta, data){
  logf = function(theta, data){
    theta[2] - log(exp(2*theta[2]) + (data - theta[1])^2)
  }
  return(sum(logf(theta,data)))
}
```
We apply the model to Darwin's famous dataset: 15 differences of the heights of cross- and self-fertilized plants quoted by Fisher (1960).  The mean is given by 
```{r}
data("darwin")
attach(darwin)
mean(difference) # mean
```
Standard deviation is 
```{r}
log(sd(difference))  
```

**Find the posterior mode** We again use `laplace` to find the posterior mode by setting the initial point of $(\mu,\lambda) = (21.6,3.6)$.
```{r}
laplace(cauchyerrorpost_mine, c(21.6,3.6), difference)  # with my function
```
```{r}
laplace(cauchyerrorpost, c(21.6,3.6), difference)  # function of LearnBayes
```

We see that the mode is given by (24.7,  2.77).  Note that `$int` is the estimate of the log integral.

We can use the result to contruct a seach space of the posterior. We take the mode +/- 4*std as the region.
```{r}
c(24.7 - 4*sqrt(34.96), 24.7 + 4*sqrt(34.96))
```
```{r}
c(2.77 - 4*sqrt(0.138), 2.77 + 4*sqrt(0.138))
```
After some trails, we decide that $\mu \in [-10, 60], \lambda \in [1,4.5]$ as the bound of `mycontour`.
```{r}
mycontour(cauchyerrorpost_mine, c(-10,60,1,4.5),difference,
          xlab="mu", ylab="log sigma")
```
This *exact* density has an interesting shape. We now try to approximate the post by **bivariate normal** by using the result of `laplace`.
```{r}
fitlaplace = laplace(cauchyerrorpost, c(21.6,3.6), difference)
mycontour(lbinorm, c(-10,60,1,4.5), 
          list(m=fitlaplace$mode,v=fitlaplace$var), 
          xlab="mu", ylab="log sigma")
```

One may notice that the normal approximation is not adequate. 







