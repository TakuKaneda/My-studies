---
title: "6. Markov Chain Monte Carlo Methods"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Cmd+Shift+Enter*. 

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Cmd+Option+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Cmd+Shift+K* to preview the HTML file). 

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

### Import the library
```{r}
library(LearnBayes) # package for the book
library(kableExtra) # for display table in HTML format
```

## 6.1 Introduction
In Chapter 5 we have seen some sampling techniques for simulation in Bayesian inference, e.g. sampling from the posterior. However, all of them (i.e. rejection sampling, impotance sampling and SIR algorithm) require a **suitable proposal density $p$**, and this choice can be difficult. 

In this chapter, we introduce Markov Chain Monte Carlo (MCMC) algorithms in summarizing posterior distribution. MCMC is very attractive because:

- easy to to set up
- easy to program
- requires relatively lttile prior info

In the following sections we see:

- 6.2: Simple random walk
- 6.3: Two variants of the Metropolis-Hastings algorithms
- 6.4: Gibbs sampling

## 6.2 Introduction to Discrete Markov Chains
Consider the following random walk problem. 

- a person takes a value in [1,...,6]
- if she is in interiors, the probabilities of stay, or move (to left or right) are equal
- if she is in edges, the probabilities stay or move to adjecent number are equal

This is a simple example of a discrete Markov chain. The transition matrix $P$ is given by:
$$
P=\begin{bmatrix}
.5 & .5 & 0 & 0 & 0 & 0 \\
.25 & .5 & .25 & 0 & 0 & 0 \\
 0 & .25 & .5 & .25 & 0 & 0 \\
 0 & 0 & .25 & .5 & .25 & 0 \\
 0 & 0 & 0 & .25 & .5 & .25 \\
 0 & 0 & 0 & 0 & .5 & .5 
\end{bmatrix}
$$

Here are some properties of Markov chain:

- *irreducible*: possible to go from any state to any state in one or more steps
- *periodic*: given a perticular state, a person can only return to the current state at regular intervals, if not it is said *aperiodic* (the random walk example is this case)

We can represent one's current position by probabilities:
$$
p = (p_1,p_2, ..., p_6)
$$
where $p_i$ is the prob that the person is in state $i$ now. If $p^j$ is the person's location at step $j$, the next position is given by
$$
p^{j+1} = p^j P.
$$
Suppose we can find a probability vector $w$ s.t.:
$$
w = wP
$$
then, $w$ is said to be the *stationaly* distribution. If a Markov chain is irreducible and aperiodic, then it has a *unique* stationaly distribution. (also the limiting distribution of this chain will be $w$)

We test it in our example. 
```{r}
# transition matrix P
P = matrix(c(.5 , .5 , 0 , 0 , 0 , 0 , .25 , .5 , .25 , 0 , 0 , 0 , 0 , .25 , .5 , .25 , 0 , 0 , 0 , 0 , .25 , .5 , .25 , 0 ,0 , 0 , 0 , .25 , .5 , .25 , 0 , 0 , 0 , 0 , .5 , .5), 
           nrow = 6, ncol = 6, byrow = T) 
P
```
Suppose we start at location 3. 
```{r}
s = array(0, c(50000,1))
s[1] = 3 # initial location
```
We simulate 50000 draws from the Markov chain. 
```{r}
for (j in 2:50000){
  s[j] = sample(1:6, size = 1, prob = P[s[j-1],]) # trans prob is  P[s[j-1],] from previous state s[j-1]
} 
```
We summarize the frequencies of visit after 500, 2000, 8000, and 50000 steps.
```{r}
m = c(500, 2000, 8000, 50000)
for (i in 1:length(m)){
  print(table(s[1:m[i]])/m[i])
}
```
We observe that the relative frequencies of the states are converging to $w=(.1,.2,.2,.2,.2,.1)$, which is the stationaly distribution. We can confirm by checkning $wP$ will be $w$. 
```{r}
w = matrix(c(.1,.2,.2,.2,.2,.1), nrow = 1, ncol = 6)
w%*%P  # %*%: matrix multiplication
```


## 6.2 Metropolis-Hastings Algorithms
The MCMC essentially is a continuous-valued generalization of the discrete Markov chain set up described in the previous section.  The MCMC sampling sets up and irreducivle, aperiodic Markov chain fro which the *stationary distribution equals the posterior distribution of interest*. The Metropolis-Hastings (MH) algorithm is used to construct such Markov chain. In this section we consider the two types of it: independence chain and random walk chain. 

Suppose we want to simulate from a post $g(\theta|y) = g(\theta)$.  A MH algorithm begins with an inital value $\theta^0$ and specifies a rule for simulating t-th value $\theta^t$ given the (t-1)st value $\theta^{t-1}$. This rule consists of a **proposal density**, which simulates a candidate value $\theta^*$, and the coputation of an **acceptance probability** $P$, which indicates the prob that the candidate value $\theta^*$ will be accepted as the next value or not. Concretely,

- Simulate a candidate value $\theta^*$ from a proposal density $p(\theta^*|\theta^{t-1})$ 
- Compute the ratio $R$ (see https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm#Formal_derivation for more details):
$$
R = \frac{g(\theta^*)p(\theta^{t-1}|\theta^*)}{g(\theta^{t-1})p(\theta^*|\theta^{t-1})}
$$
- Compute the acceptance prob $P= \min\{R,1\}$.
- Sample a value $\theta^t$ s.t. $\theta^t=\theta^*$ with prob $P$; otherwise $\theta^t=\theta^{t-1}$

Under some conditions on the proposal density $p(\theta^*|\theta^{t-1}$, the simulated draws $\theta_1,\theta_2,...$ will **converge to a r.v. that is distributed according to $g(\theta)$.**

*More on the acceptance rate*: We want to find a probability $p$ such that:
$$
g(x)p(y|x) = g(y)p(x|y)
$$
where left = prob(getting y from x) and right = prob(getting x from y). We call this as *reversibility condition*. However, most of the cases we have:
$$
g(x)q(y|x) > g(y)q(x|y)
$$
or the opposite ($<$). It says "getting y from x is too often while getting x from y is too rare". Hence we want to somehow *correct* this condition by introducing an acceptance rate $A(x, y)<1$. We can see $A(x, y)<1$ as *probability of move*. The transition from x to y is given by
$$
p_{HM}(y|x) = A(x, y)q(y|x)
$$
where $A(x, y)<1$ is not defined yet. From the above inequality, we should set $A(y, x)=1$, i.e. transition from y to x must occures more. On the other hand, the prob of move from x to y should satisfy the reversibility condition for $p_{HM}$, hence,
$$
\begin{aligned}
g(x) A(x, y)q(y|x) &=  g(y)A(y, x)q(x|y)\\
&= g(y)q(x|y)
\end{aligned}
$$
Thus we have:
$$
A(x, y) = \begin{cases}\min \{1,\frac{g(y)q(x|y)}{g(x)q(y|x)}  \}, g(x)q(y|x)>0\\
1, \text{otherwise}
\end{cases}
$$

#### Independent case
If the proposal density $p$ is independent of the current state: 
$$
p(\theta^*|\theta^{t-1})  =p(\theta^*)
$$
then the algorithm is called an *independence chain*. This can be implemented by `indepmetrop` in `LearnBayes`

#### Symmetric case (random walk)
If the proposal density $p$ is symmetric density:
$$
p(\theta^*|\theta^{t-1})  = h(\theta^*-\theta^{t-1})
$$
where $h$ is a  symmetric density about the origin, then this type of *random walk* chain has the ratio $R$ s.t.:
$$
R = \frac{g(\theta^*)}{g(\theta^{t-1})}
$$
 This can be implemented by `rwmetrop` in `LearnBayes`.
 
 Desireble features of $p$ depends on the choice of MCMC algorithm. We need to be careful about the rate $g/p$ to be bounded as befor. The proposal $p$ is "best" if the acceptance ratio ranges between 25%-45% (but depends on the dimension). 
 
 ### 6.4 Gibbs Sampling
 Another setting up of MCMCis Gibbs sampling. Suppose our interest parameter is $\theta=(\theta_1,...,\theta_d)$. The joint posterior $[\theta|data]$ may be of high dim and difficult to simulate. Hence we set the following set of $d$ conditional distributions:
 $$
 [\theta_1|\theta_2,...,\theta_d,data],\\
 [\theta_2|\theta_1,\theta_3,...,\theta_d,data],\\
 ...\\
 [\theta_d|\theta_1,...,\theta_{d-1},data],\\
 $$
 The idea of Gibbs sampling is that we can set up a Markov chain simulation algorithm from the joint posterior by successfully simulating individual params from the set of $d$ conditional distributions. It is known that *under general conditions, draws from this simulation will converge to the target distirubiton $[\theta|data]$*. 
 
In cases where it is not convenient to sample directly from the conditional dist, one can apply a MH algorithm with a random walk proposal. Suppose $\theta^t_i$ is the current value of $i$th componet of the parameter vector, and let $g(\theta_i)$ be the conditional dist with suppressed dependence of $\theta_{(-i)}$. Then one possible approach of giving a candidate value is:
$$
\theta_i^* = \theta_i^t + c_i Z_i
$$
where $c_i$ is a scale constant and $Z_i$ is a standard normal r.v.. The next value $\theta_i^{t}$ will be $\theta^*$ with probability $P=\min\{1,g(\theta^*)/g(\theta^{t})\}$; otherwise $\theta_i^{t+1} = \theta_i^{t}$. This process can be implemeted by the `R` function `gibbs` in `LearnBayes`.

## 6.5 MCMC Output Analysis 
Although the theoreis give that the j-th simulation $\theta^j$ converges to a draw from the true posterior if $j$ goes infinity, there is no practical guidance on it. Hence, we need to assess the performance by plotting or computing diagnostic statistics etc..

## 6.7 Learning About a Normal Population from Grouped Data
The first example: random sample taken from a normal populatino with mean $\mu$ and std $\sigma$, but only observes in "grouped" form. Our problem is about the mean and std of the heights of men from a local college. 

Height interval (in.)/ Frequency

- < 66 / 14
- [66, 68] / 30
- [68, 70] / 49
- [70, 72] / 70
- [72, 74] / 33
- < 74 / 15

We observe the unknow bin probs: $p_i,i=1,...,6$. e.g. the heigth is in [66,68] is given by $p_2 = \Phi(68,\mu,\sigma) - \Phi(66,\mu,\sigma)$, where $\Phi(;,\mu,\sigma)$ is the cdf of Normal. The likelihood is given as:
$$
\begin{aligned}
L(\mu,\sigma) & \propto \Phi(66,\mu,\sigma)^{14}(\Phi(68,\mu,\sigma)-\Phi(66,\mu,\sigma))^{30}\\
& \times  (\Phi(70,\mu,\sigma)-\Phi(68,\mu,\sigma))^{49} \\
&  \cdots\\
& \times  (1-\Phi(74,\mu,\sigma))^{15}
\end{aligned}
$$
Suppose $(\mu,\sigma)$ are assigned the usual noniformative prior, then the posterior is proportional to 
$$
g(\mu,\sigma) \propto \frac{1}{\sigma}L(\mu,\sigma).
$$
To make the params to be real-valued line, $\lambda = \log(\sigma)$, and the posterior of $(\mu,\lambda)$ is given by
$$
g(\mu,\lambda) \propto L(\mu, \exp(\lambda)).
$$
Here we define a function `groupeddatapost` that computes the log of the post of $(\mu,\lambda)$. 
```{r}
groupeddatapost = function(theta,data){ 
  # theta: (mu, lambda), 
  # data$int.lo: lower bound, data$int.hi: higher bound, data$f: frequency
  dj = function(f, int.lo, int.hi, mu, sigma){
    f * log(pnorm(int.hi, mu, sigma) - pnorm(int.lo, mu, sigma))
  }
  mu = theta[1]
  sigma = exp(theta[2])
  sum(dj(data$f, data$int.lo, data$int.hi, mu, sigma))
}
```
We define the data
```{r}
d = list(int.lo = c(-Inf, seq(66,74, by = 2)),
         int.hi = c(seq(66,74, by = 2), Inf),
         f = c(14, 30, 49, 70, 33, 15))
```
To decide the *initial point* (to use the function `laplace`), we require a good guess at the location of the post mode. To estimate the mode of $(\mu, \log \sigma)$, we replace the bin to the mid-point. Then, use the sample mean and std of the artificial data.
```{r}
y = c(rep(65,14), rep(67,30), rep(69,49), rep(71,70),rep(73,33),rep(75,15))
mean(y)
```
```{r}
log(sd(y))
```
Based on this, we believe that $(\mu, \log \sigma) \approx (70,1)$. We find the posterior by using `laplace`.
```{r}
start = c(70,1)
fit = laplace(groupeddatapost, start, d) #Summarization of a posterior density by the Laplace method
fit
```
Hence the posterior mode of $(\mu, \log \sigma)$ is found to be (70.17,0.97). The associated stds can be computed as:
```{r}
modal.sds = sqrt(diag(fit$var)) # sqrt of diag of the covariance matrix
modal.sds
```
We use this result to design a MH random walk algorithm. For the *proposal density* $p$, we use **t-distribution** with the covariance matrix of `laplace` and the scale parameter 2 . We run 10000 iterations of the random walk algorithm starting from `start`. 
```{r}
proposal = list(var=fit$var, scale=2)
fit2 = rwmetrop(groupeddatapost, proposal, start, 10000, d) # run the HM random walk algo
```
We monitor the algorithm by the acceptance rate $R$.
```{r}
fit2$accept
```
We now be able to summarize the params by computing the posterior means and stds.
```{r}
post.means = apply(fit2$par,2,mean)
post.sds = apply(fit2$par,2,sd)
```
We can access the accuracy of the model by comparing the result of `laplace` (optimization).
```{r}
cbind(post.means, post.sds) # result of MCMC
```
```{r}
cbind(c(fit$mode),modal.sds) # result of laplace (optimization)
```
Finally we see the result by plotting.
```{r}
mycontour(groupeddatapost, c(69,71,0.6,1.3),data = d,
          xlab="mu",ylab="log sigma")
points(fit2$par[5001:10000,1],fit2$par[5001:10000,2]) # plot the last 5000 samples
```


## 6.8 Example of Output Analysis
In order to perform the output analysis of MCMC algorithm, we use `coda` which will be described in chapter 11. Suppose we rerun the MH rw algorthm for the previous problemw with **poor choices of initial value and proposal density $p$**. We set the inital as (65,1) (instead of (70,1)) and the scale of 0.2 of $p$  (instead of 2).
```{r}
start = c(65,1)
proposal = list(var = fit$var, scale = 0.2)
```
We then rerun the algo.
```{r}
bayesfit = rwmetrop(groupeddatapost, proposal = proposal, start = start, m = 10000, d)
bayesfit$accept
```
We observe that acceptance rate of 89% which is pretty high. In this example we consider the first 2000 iterations as the burn-in period thus dicard them. 
```{r}
library(coda) # for assessing the MCMC result
library(lattice) # for xyplot
dimnames(bayesfit$par)[[2]] = c("mu","log sigma")
xyplot(mcmc(bayesfit$par[-c(1:2000),]),col="black")
```

We observe that the simulated draws reached the main support of the posterior of $\mu$. However, the sequence appears irregular: it explores  $\mu > 70.5$ for a while which is not relevant. We hence see the strong autocorrelation 
```{r}
#par(mfrow=c(2,1))
autocorr.plot(mcmc(bayesfit$par[-c(1:2000),]),auto.layout = T)
```
The autocorrelations are close to 1 in Lag1, and decrease very slowly.

The `summary` of `mcmc` output gives the empirical mean and sd for each param. The `Naive SE` is computed as the draws are fully independent sample ($\sigma_{SE} = \sigma/\sqrt{n}$), hence the value is very small (e.g. 0.002 for $\mu$) . However, `BatchSE` gives the more more accurate estimate. (we assume *a batch of data* is independent)
```{r}
 summary(mcmc(bayesfit$par[-c(1:2000),]))
 batchSE(mcmc(bayesfit$par[-c(1:2000),]), batchSize=50) # batch size = 50
```
We compare this result with the previously obtained more accurate one (start point = (70,1), scale of $p$ is 2)
```{r}
 summary(mcmc(fit2$par[-c(1:2000),]))
 batchSE(mcmc(fit2$par[-c(1:2000),]), batchSize=50) # batch size = 50
```
We see that `batchSE` are now very small. Also check by plotting. 
```{r}
dimnames(fit2$par)[[2]]=c("mu","log sigma")
xyplot(mcmc(fit2$par[-c(1:2000),]),col="black")  # result of samples
```
```{r}
autocorr.plot(mcmc(fit2$par[-c(1:2000),]),auto.layout = T) # autocorr
```

The parameters appear more *random noise*. For the autocorrelation, it is near 1 for lag 1 and decreases very rapidly. 


## 6.9 Modeling Data with Cauchy Errors
The second example is to see what happens with **outliers**.
We here test a Cauchy density (t distribution with a single degree of freedom). 

Suppose we observe data $y_i$ from a Cauchy density of location paramter $\mu$ and scale paramter $\sigma$,
$$
f(y|\mu,\sigma) = \frac{1}{\pi \sigma(1+z^2)}
$$
where $z = \frac{y-\mu}{\sigma}$. Suppose we use the usual noninformative prior:
$$
g(\mu,\sigma) \propto \frac{1}{\sigma}
$$
Then, the posterior is given by:
$$
\begin{aligned}
g(\mu,\sigma|data)& \propto g(\mu,\sigma) \prod_{i}f(y_i|\mu,\sigma)\\
& =  \frac{1}{\sigma} \prod_{i}[\frac{1}{\sigma(1+(\frac{y_i-\mu}{\sigma})^2)}]
\end{aligned}
$$
As always, we replace the variable $\sigma$ by $\lambda = \log(\sigma)$.
$$
\begin{aligned}
g(\mu,\lambda|data) &\propto  \prod_{i}[\frac{1}{e^\lambda(1+(\frac{y-\mu}{e^\lambda})^2)}]\\
& = \prod_{i}[\frac{e^\lambda}{e^{2\lambda} + (y_i-\mu)^2}]
\end{aligned}
$$
The log of the density is:
$$
\log(g(\mu,\lambda|data)) = \sum_i [\lambda - \log(e^{2\lambda} + (y_i-\mu)^2)]
$$ 
We define the funtion `cauchyerrorpost_mine` (`LearnBayes` has `cauchyerrorpost`) to compute $\log(g(\mu,\lambda|data))$:
```{r}
cauchyerrorpost_mine = function(theta, data){
  logf = function(theta, data){
    theta[2] - log(exp(2*theta[2]) + (data - theta[1])^2)
  }
  return(sum(logf(theta,data)))
}
```
We apply the model to Darwin's famous dataset: 15 differences of the heights of cross- and self-fertilized plants quoted by Fisher (1960).  The mean is given by 
```{r}
data("darwin")
attach(darwin)
mean(difference) # mean
```
Standard deviation is 
```{r}
log(sd(difference))  
```

**Find the posterior mode** We again use `laplace` to find the posterior mode by setting the initial point of $(\mu,\lambda) = (21.6,3.6)$.
```{r}
laplace(cauchyerrorpost_mine, c(21.6,3.6), difference)  # with my function
```
```{r}
laplace(cauchyerrorpost, c(21.6,3.6), difference)  # function of LearnBayes
```

We see that the mode is given by (24.7,  2.77).  Note that `$int` is the estimate of the log integral.

We can use the result to contruct a seach space of the posterior. We take the mode +/- 4*std as the region.
```{r}
c(24.7 - 4*sqrt(34.96), 24.7 + 4*sqrt(34.96))
```
```{r}
c(2.77 - 4*sqrt(0.138), 2.77 + 4*sqrt(0.138))
```
After some trails, we decide that $\mu \in [-10, 60], \lambda \in [1,4.5]$ as the bound of `mycontour`.
```{r}
mycontour(cauchyerrorpost_mine, c(-10,60,1,4.5),difference,
          xlab="mu", ylab="log sigma")
```
This *exact* density has an interesting shape. We now try to approximate the post by **bivariate normal** by using the result of `laplace`.
```{r}
fitlaplace = laplace(cauchyerrorpost, c(21.6,3.6), difference)
mycontour(lbinorm, c(-10,60,1,4.5), 
          list(m=fitlaplace$mode,v=fitlaplace$var), 
          xlab="mu", ylab="log sigma")
```

One may notice that the normal approximation is not adequate. However, the estimated covariance matrix is useful for setting up MH random-walk chain. We here set the scale as 2.5 and the `start` as (20,3).
```{r}
proposal = list(var=fitlaplace$var, scale=2.5)
start = c(20,3)
m = 1000 # number of simulation
s = rwmetrop(cauchyerrorpost, proposal = proposal, start = start, m = m, difference)
mycontour(cauchyerrorpost, c(-10,60,1,4.5), difference,
          xlab="mu", ylab="log sigma")  # contour plot
# scatter plot of the simulation
points(s$par[,1], s$par[,2])
```

We then see the empirical density estimation of two approaches.
```{r}
start=c(20,3)
rw = rwmetrop(cauchyerrorpost, proposal = proposal, start = start, m = 50000, difference)
```

```{r}
curve(dnorm(x, mean = fitlaplace$mode[1], sd = sqrt(fitlaplace$var[1,1])),from = -20,to = 60, xlab = "mu", ylab = "Posteriror Density", lwd = 2, lty = 2)
d = density(rw$par[,1])
#par(new=TRUE)
lines(d, lwd = 3)
legend("topleft", legend=c("normal", "random walk"), lty = c(2,1), lwd = c(2,3))
```


**Comparison of Algorithms**

Here we consider the comparison of the following algorithms: 

- "brute-force": simulate $(\mu,\log\sigma)$ by using `simcontour`. 
- MW random walk: we have did.
- MH independence chain: the proposal $p$ is independent $p(\theta^*|\theta^{t-1})=p(\theta^*)$.
- Gibbs sampling with scale (12, 0.75): the scale is aobut 2*sd of `laplace` fit.

```{r}
library(mvtnorm) # multi-variate noraml
fitnorm = rmvnorm(50000,mean = fitlaplace$mode, sigma = fitlaplace$var)
```

```{r}
# brute-force
fitgrid = simcontour(cauchyerrorpost, c(-10,60,1,4.5), difference, 50000)
# MH random-walk
proposal = list(var=fitlaplace$var, scale = 2.5)
start = c(20,3)
fitrw = rwmetrop(cauchyerrorpost, proposal, start, 50000, difference)
# MH independence
proposal2 = list(var=fitlaplace$var, mu=t(fitlaplace$mode))
fitindep = indepmetrop(cauchyerrorpost, proposal2, start, 50000, difference)
# Gibbs
fitgibbs = gibbs(cauchyerrorpost,start,50000,c(12,.75),difference)
```

The simulated draws can be summarized as
```{r} 
cbind(quantile(fitrw$par[,1],c(.05,.5,.95)), quantile(fitrw$par[,2],c(.05,.5,.95)))
```
```{r}
cbind(quantile(fitindep$par[,1],c(.05,.5,.95)), quantile(fitindep$par[,2],c(.05,.5,.95)))
```
```{r}
par(mfrow=c(1,2))
boxplot(fitnorm[,1],fitgrid$x,fitrw$par[,1],fitindep$par[,1],fitgibbs$par[,1],names = c("norm","b-f","r-w","ind","gib"),ylab="mu")
boxplot(fitnorm[,2],fitgrid$y,fitrw$par[,2],fitindep$par[,2],fitgibbs$par[,2],names = c("norm","b-f","r-w","ind","gib"),ylab="log simga")
```

We observe that the normal approximation is far from the other methods: thinner tails for $\mu$, and different mean for $\log \sigma$.
The acceptance rates are:
```{r}
cbind(fitrw$accept,fitindep$accept,fitgibbs$accept)
```
The independent method has higher acceptance rate.


## 6.10 Analysis of the Stanford Heart Transplant Data
Turnbull et al (1974) describe a number of approaches for analyzing heart transplant data from the Stanford Heart Transplanation Program. One of the gols is to **decide if heart transplanation extends a patient's life**. One of their models, the Pareto Model (section 4.3): assuming that the lifetime $t$ of a patient follow an exponential distribution $f(t|\theta)$ with mean $1/\theta$ where $\theta$ is *mortalityor hazard*, and is assumed to follow a gamma distribution $f(\theta)$, i.e.:
$$
f_{non}(t|\theta) = \theta e^{-\theta t}, t \geq 0\\
f(\theta;\lambda,p) = \frac{\lambda}{\Gamma(p)}(\lambda\theta)^{p-1} e^{-\lambda\theta}
$$

We also suppose that the transplant group has a similar exponential distribution with mean $1/\tau\theta$. So the risk is given by a constant unknown parameter $\tau>0$.
$$
f_{trans}(t|\tau\theta) = \tau\theta e^{-\tau\theta t}, t \geq 0
$$
Notations:

- $N$ non-transplant patients, $n$ are died and $N-n$ are alive.
- $M$ transplant patients, $m$ are died and $M-m$ are alive.
- $x_i$: actual survival time to death or closing date (for non-transplant group) (in days)
- $y_j$: time to transplant (for transplant group)
- $z_j$: days from transplan to death or closing date (for transplant group)

Then, we want to know the unknowm params $(\tau,\lambda,p)$. The likelihood is given by
$$
L(\tau,\lambda,p) = \prod_{i=1}^n\frac{p\lambda^p}{(\lambda+x_i)^{p+1}} \prod_{i=n+1}^N\frac{\lambda^p}{(\lambda+x_i)^{p}}\\
\times \prod_{j=1}^m\frac{\tau p\lambda^p}{(\lambda+y_i+\tau z_j)^{p+1}} \prod_{j=m+1}^M\frac{\lambda^p}{(\lambda+y_i+\tau z_j)^{p}}
$$

**proof**: The mariginal distribution of lifetime is given by:
$$
f(t) = \int f(t|\theta)f(\theta)d\theta\\
= \int \theta e^{-\theta t} \cdot \frac{\lambda}{\Gamma(p)}(\lambda\theta)^{p-1} e^{-\lambda\theta} d\theta\\
= \frac{\lambda^p\Gamma(p+1)}{\Gamma(p)(\lambda+t)^{p+1}}\int \frac{\theta^p}{\Gamma(p+1)}(\lambda+t)^{p+1} e^{-(\lambda+t)\theta}d\theta\\
= \frac{p\lambda^p}{(\lambda+t)^{p+1}}\cdot1
$$

We here consider the uniform prior hence the posterior is proportional to the likelihood. Also, we transform the parameters by log as always:
$$
\theta = (\theta_1,\theta_2,\theta_3) = (\log \tau, \log \lambda, \log p)
$$
Then, the post density $\theta$ is given by:
$$
g(\theta|data) \propto L(e^\tau,e^\lambda,e^p)\prod_{i=1}^3e^{\theta_i}
$$
since $d\tau = e^{\theta_1}d\theta_1$, etc. 

We now try to write a script in `R`.
```{r}
# read data
data("stanfordheart")
attach(stanfordheart)
head(stanfordheart)
```

where `transplant` is the indicator of transplant, and the `state` represents wheather the patient is died 0 or alive 1.  
The following funciton `transplantpost` computes the log posterior with input $\theta$ `theta` and observation `data`.
```{r}
transplantpost = function(theta, data){
  x = data[,1] # survive time
  y = data[,3]  # time to transplant
  ind = data[,2]  # transplantation or not
  d = data[,4] # died or not
  # retrieve params
  tau = exp(theta[1])
  lambda = exp(theta[2])
  p = exp(theta[3])
  # non-transplant group
  xnt = x[ind==0]
  dnt = d[ind==0]
  # transplant group
  z = x[ind==1]
  y = y[ind==1]
  dt = d[ind==1]
  # log likelihood-non-transplant group 
  logf = function(xnt, dnt, lambda, p){
    ((dnt==0)* (p * log(lambda) + log(p) - (p + 1) * log(lambda + xnt)) + 
    (dnt==1)* p * log(lambda/(lambda + xnt)))
  }
  # log likelihood-transplant group
  logg = function(z,y,tau,lambda,p){
    ((dt == 0) * (p * log(lambda) + log(p * tau) - (p + 1) * log(lambda + y + tau*z)) + 
    (dt == 1) * p * log(lambda/(lambda + y + tau*z)))
  }
  val = sum(logf(xnt, dnt, lambda, p))+sum(logg(z,y,tau,lambda,p))
  val = val + theta[1]+theta[2]+theta[3]
  return(val)
}
```

To get the inital starting point, we again use `laplace`. Our ininal guess is (0,3,-1).
```{r}
start = c(0,3,-1)
laplacefit = laplace(transplantpost, start, stanfordheart)
laplacefit
```

We use the MH random walk algortithm with proposal variance of $2V$. The acceptance rate is 0.19.
```{r}
proposal = list(var = laplacefit$var, scale=2)
s = rwmetrop(transplantpost, proposal, start, 10000, stanfordheart)
s$accept
```

We here see the density of the parameters $\theta$.
```{r}
par(mfrow=c(2,2))
tau = exp(s$par[,1])
plot(density(tau),main="TAU")
lambda = exp(s$par[,2])
plot(density(lambda),main="LAMBDA")
p = exp(s$par[,3])
plot(density(p),main="P")
```

From the figure, we see that $\tau $ has the mass around 1, thus we cannot say that $\tau \neq 1$. This implies that **we cannot say the transpalent makes the risk of death higher or lower.** 
 The 5, 50 and 95% percentile of the parameters are given by:
```{r}
apply(exp(s$par),2,quantile,c(.05,.5,.95))
```

Recall that the survival curve of a patient is given by 
$$
S(t) = P[T>t] = 1 - P[T\leq t] \\
= 1 - \int_0^t \frac{p\lambda^p}{(\lambda+x)^{p+1}} dx = 1 - ( - \frac{\lambda^p}{(\lambda+t)^{p}}+1) \\
= \frac{\lambda^p}{(\lambda+t)^{p}}
$$
We try to plot the survival curve in this case with 5, 50, 95% quantiles of them.
```{r}
t = seq(1,240) # the value (in day) of survival date
p5 = 0*t; p50 = 0*t; p95 = 0*t
for (j in 1:length(t)){
  S = (lambda/(lambda+t[j]))^p  # value of S(t)
  q = quantile(S, c(.05, .5, 0.95)) # quantiles
  p5[j] = q[1]; p50[j] = q[2]; p95[j] = q[3]
}
plot(t,p50, type = "l", ylim =c(0,1),ylab = "Prob(Survival)",xlab = "Time")
lines(t, p5, lty = 2)
lines(t, p95, lty = 2)
```
 
